{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Custom extra width cells\n",
    "from IPython.core.display import HTML, display\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests,pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'census_key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c83a6c2da241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'census_key.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'census_key.txt'"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "\n",
    "api_key = \"\"\n",
    "# Get the key\n",
    "# with open(f'census_key.txt') as key:\n",
    "#     api_key=key.read().strip()\n",
    "    \n",
    "# # print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_col_stats(df_missing):\n",
    "    # Get the missing values per each column \n",
    "    missing_series = df_missing.isna().sum()\n",
    "\n",
    "    # Concatunate each column's type so we have a better idea for imputation\n",
    "    missing_types_df = pd.concat([missing_series.rename('Missing'), df_missing.dtypes.rename('Dtype')], axis=1)\n",
    "    missing_types_df.sort_values(by=['Missing'], ascending=False, inplace=True)\n",
    "    display(missing_types_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEO_ID Mapping via Relationship file\n",
    "Since the postal code average income api response only returns a GEO_ID per zipcode, we first want to get all the GEO_IDs and their corresponding state and counties to cross reference in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All relationdship files: https://www2.census.gov/geo/pdfs/maps-data/data/rel/\n",
    "# https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_place_rel_10.txt\n",
    "\n",
    "# https://opendata.stackexchange.com/a/13731\n",
    "# Read in the ZCTA5 to PLACE & STATE file\n",
    "zcta_place_relations_df = pd.read_csv(\"zcta_place_rel_10.txt\")\n",
    "\n",
    "# Only keep the columns we want to merge\n",
    "zcta_place_relations_df = zcta_place_relations_df[[\"ZCTA5\", \"STATE\", \"PLACE\"]]\n",
    "\n",
    "# Need to rename the columns so they can be matched on the next step\n",
    "new_col_names = {\"STATE\": \"State_id\", \"PLACE\":\"Place_id\"}\n",
    "zcta_place_relations_df.rename(columns = new_col_names, inplace = True)\n",
    "\n",
    "# Output stats\n",
    "print(f\"Place list amount -> {len(zcta_place_relations_df.index)}\")\n",
    "display(zcta_place_relations_df.head())\n",
    "\n",
    "# Test a match 28277\n",
    "zcta_place_relations_df.loc[zcta_place_relations_df.index == 28277]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Place and State IDs to their actual names\n",
    "We first want to request the actual names for the state and place ids. And then we can add the ZCTA to this file, which is needed for matching the houeshold incomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for census GEO_IDs call\n",
    "year='2018'\n",
    "dsource='acs' # American Cummunity Survey\n",
    "dname='acs5' # 5 year survey\n",
    "\n",
    "# B19001_001 -> HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2019 INFLATION-ADJUSTED DOLLARS)\n",
    "cols='NAME,GEO_ID'\n",
    "geography_state = 'place:*'\n",
    "# https://api.census.gov/data/2018/acs/acs5?key=&get=B19001_001E,NAME,COUNTY,GEO_ID&for=zip%20code%20tabulation%20area:*%20state:*\n",
    "\n",
    "\n",
    "def map_geoids_to_df(response_geos):\n",
    "    # Read the data to json\n",
    "    data = response_geos.json()\n",
    "\n",
    "    # Create the df\n",
    "    df_geoids = pd.DataFrame(data[1:], columns=data[0]).\\\n",
    "        rename(columns={\"NAME\": \"Place_state\", \"place\": \"Place_id\",\n",
    "                        \"state\": \"State_id\", \"GEO_ID\":\"gid\"})\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/a/61313413/8970591\n",
    "    # Seperate the format 'place, state' to 2 seperate columns\n",
    "    df_geoids[['Place', 'State']] = df_geoids['Place_state'].str.split(',', n=1, expand=True)\n",
    "    # df_geoids.drop(columns=['County_state', 'State_id', 'County_id'], inplace=True)\n",
    "#     df_geoids.set_index('gid', inplace=True)\n",
    "\n",
    "    # Convert to integer so we can match it with the place/state file indexes\n",
    "    df_geoids['Place_id'] = df_geoids['Place_id'].astype(int)\n",
    "    df_geoids['State_id'] = df_geoids['State_id'].astype(int)\n",
    "\n",
    "\n",
    "    # Ouput the results\n",
    "    display(df_geoids.head())\n",
    "    \n",
    "    return df_geoids\n",
    "\n",
    "def geo_id_mapping_df():\n",
    "\n",
    "    base_url = f'https://api.census.gov/data/{year}/{dsource}/{dname}'\n",
    "    # url_zip = \"https://api.census.gov/data/2017/acs/acs5?get=NAME,group(B19013)&for={geography}\"\n",
    "\n",
    "\n",
    "    # &for=zip%20code%20tabulation%20area:*\"\n",
    "    data_url = f'{base_url}?key={api_key}&get={cols}&for={geography_state}'\n",
    "    \n",
    "    # Get the census data\n",
    "    response_geos = requests.get(data_url)\n",
    "       \n",
    "    # Convert to df and return\n",
    "    return map_geoids_to_df(response_geos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to match the actual place and state names to this file\n",
    "geo_ids_df = geo_id_mapping_df()\n",
    "display(geo_ids_df.info())\n",
    "\n",
    "# Finally merge the the ZCTA to this file\n",
    "# Merge place and state id with each ZCTA row\n",
    "zcta_place_best = geo_ids_df.merge(zcta_place_relations_df, how = 'inner', on = ['State_id', 'Place_id'])\n",
    "\n",
    "# Now we can remove the columns we do not need anymore\n",
    "drop_cols = ['gid', 'Place_id', 'State_id']\n",
    "zcta_place_best.drop(columns = drop_cols, inplace=True)\n",
    "\n",
    "# Set to index so we can match it\n",
    "zcta_place_best.set_index('ZCTA5', inplace=True)\n",
    "zcta_place_best.index.name = 'ZCTA5'\n",
    "\n",
    "# Ouput the results\n",
    "display(zcta_place_best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly do our nan check to see if anything did not match\n",
    "get_nan_col_stats(zcta_place_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting coordinates for each zipcode\n",
    "We want this data, so we can add these columns to our income df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://download.geonames.org/export/zip/\n",
    "dtypes_dict = {\n",
    "    0: str, # country code  \n",
    "    1: str,  # postal code \n",
    "    2: str,  # place name \n",
    "    \n",
    "    3: str,  # admin name1  order subdivision (state) varchar(100)\n",
    "    4: str, # admin code  subdivision (state) varchar(20)\n",
    "    5: str, # admin name2  subdivision (county/province) varchar(100)\n",
    "    6: str, # admin code  (county/province) varchar(20)\n",
    "    7: str, # admin name3 (community) varchar(100)\n",
    "    8: str, # admin code3  (community) varchar(20)\n",
    "    \n",
    "    9: float, # latitude\n",
    "    10: float, # longitude\n",
    "    11: float, # accuracy of lat/lng\n",
    "}\n",
    "\n",
    "us_zip_df = pd.read_csv(f\"{data_dir}/US_zip.txt\", sep=\"\\t\", \n",
    "            usecols=(0, 1, 2, 3, 4, 5, 6,  9, 10, 11), index_col=0,\n",
    "            names=('country_code', 'postal_code', 'place_name', \n",
    "                   'state', 'state_code', 'county_sub', 'county_code',\n",
    "                   'latitude', 'longitude', 'acc_lat_long'), dtype=dtypes_dict)\n",
    "\n",
    "\n",
    "# We only want to keep the coordinates and their accuracy\n",
    "us_zip_df = us_zip_df[[\"postal_code\", \"latitude\", \"longitude\", \"acc_lat_long\"]]\n",
    "us_zip_df['zipcode_ta'] = us_zip_df['postal_code'].astype(int)\n",
    "\n",
    "# Drop any nan values for the selection of columns we need\n",
    "us_zip_df.dropna(inplace=True) \n",
    "\n",
    "# # Set index to zipcode for merging\n",
    "us_zip_df.set_index('zipcode_ta', inplace=True)\n",
    "\n",
    "# Validate the output\n",
    "display(us_zip_df.head())\n",
    "\n",
    "get_nan_col_stats(us_zip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the average household income data and matching coordinates\n",
    "We will now fetch the average household income data by zipcode and then match the county and city name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# American Cummunity Survey\n",
    "dsource='acs'\n",
    "dname='acs5' # 5 year survey\n",
    "\n",
    "# B19001_001 -> HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2019 INFLATION-ADJUSTED DOLLARS)\n",
    "cols='B19001_001E'\n",
    "\n",
    "# https://api.census.gov/data/2018/acs/acs5?key=&get=B19001_001E,NAME,COUNTY,GEO_ID&for=zip%20code%20tabulation%20area:*%20state:*\n",
    "geography_zip = 'zip%20code%20tabulation%20area:*'\n",
    "\n",
    "\n",
    "def add_coordinates_to_zip(df_inc):\n",
    "    # Add coordinates to the zipcodes by merging\n",
    "    # Left join since we want to add the columns for the df_inc table\n",
    "    df_final = df_inc.merge(us_zip_df, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Drop unmatched columns\n",
    "    df_final.dropna(inplace=True)\n",
    "\n",
    "    # Ouput results\n",
    "    # print(len(df_inc.index))\n",
    "    # print(len(us_zip_df.index))\n",
    "    # print(len(df_final.index))\n",
    "    \n",
    "    return df_final\n",
    "    \n",
    "\n",
    "def create_and_income_df(response_inc, year):\n",
    "    # Read the data to json\n",
    "    data = response_inc.json()\n",
    "\n",
    "    # Create the df\n",
    "    df_inc = pd.DataFrame(data[1:], columns=data[0]).\\\n",
    "        rename(columns={\"B19001_001E\": \"Avg_household_inc\",\n",
    "                        \"zip code tabulation area\": \"zipcode_ta\"})\n",
    "\n",
    "\n",
    "    # Convert to integer so we can match it with the place/state file indexes\n",
    "    df_inc['zipcode_ta'] = df_inc['zipcode_ta'].astype(int)\n",
    "    df_inc.set_index('zipcode_ta', inplace=True)\n",
    "    \n",
    "    # Drop columns with no household inc info\n",
    "    df_inc.dropna(inplace=True)\n",
    "\n",
    "    # Add coordinates\n",
    "    df_inc = add_coordinates_to_zip(df_inc)\n",
    "    \n",
    "    # Ouput the results\n",
    "    # display(df_inc.head())\n",
    "    \n",
    "    return df_inc\n",
    "\n",
    "\n",
    "def get_acs5_inc_cencus_data_for_year_as_df(year):\n",
    "    # Get base url for year\n",
    "    base_url = f'https://api.census.gov/data/{year}/{dsource}/{dname}'\n",
    "\n",
    "    # Get final url and make the request\n",
    "    data_url = f'{base_url}?get={cols}&for={geography_zip}&key={api_key}'\n",
    "    response = requests.get(data_url)\n",
    "    \n",
    "    return create_and_income_df(response, year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each year we want the data from\n",
    "# 2019 and 2020 are not available yet...\n",
    "years = ['2015', '2016', '2017', '2018']\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Requesting income data for year {year}....\")\n",
    "\n",
    "    # Get this year's df with ZCTA as index\n",
    "    df_inc = get_acs5_inc_cencus_data_for_year_as_df(year)\n",
    "    \n",
    "    # Merge place and state with each ZCTA row\n",
    "    df_final = pd.merge(df_inc, zcta_place_best, left_index=True, right_index=True)\n",
    "    df_final.index.name = 'ZCTA5'\n",
    "    \n",
    "    # Drop columns we don't need anymore\n",
    "    \n",
    "    # Output the results\n",
    "    # display(df_final.head())\n",
    "    \n",
    "    # Validate of each ZCTA is matched\n",
    "    get_nan_col_stats(df_final)\n",
    "    \n",
    "    # Write to disk\n",
    "    print(f\"Going to write income data for year {year}....\")\n",
    "    df_final.to_csv(f\"{data_dir}/census_inc_{year}\", encoding='utf-8')\n",
    "\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
