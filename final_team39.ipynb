{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Final Project: Police Violence Investigation\n",
    "\n",
    "### Initial Exploratory Data Analysis\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Team Members**: Chika Okafor, Vasco Meerman, Matthew Parker, and David Koupaei\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML, display\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "## README\n",
    "\n",
    "### Layout\n",
    "#### Section 1: Look at mapping police data set\n",
    "\n",
    "* Goals\n",
    "    * See the state of the data\n",
    "    * Determine if any cleaning is necessary\n",
    "    * Perform cleaning\n",
    "    * Initial snapshot look for trends\n",
    "    * Identify which predictors might be useful\n",
    "    \n",
    "#### Section 2: Look at Wapo data set\n",
    "\n",
    "* Goals\n",
    "    * See the state of the data\n",
    "    * Determine if any cleaning is necessary\n",
    "    * Perform cleaning\n",
    "    * Initial snapshot look for trends\n",
    "    * Identify which predictors might be useful\n",
    "    \n",
    "#### Section 3: Make some Plots\n",
    "\n",
    "* Goals\n",
    "    * Start to generate plots\n",
    "    \n",
    "    \n",
    "#### Section 4: Initial look at models\n",
    "\n",
    "* Goals\n",
    "    * Now that the data is understood, take a look at initial models\n",
    "    * Try a few options and review for feasibility and utility\n",
    "    \n",
    "    \n",
    "\n",
    "## Contents\n",
    "- [Section 1: Looking at Mapping Police Violence Dataset](#Section-1:-Looking-at-Mapping-Police-Violence-Dataset) \n",
    "- [Section 2: Now look at Washington Post Data](#Section-2:-Now-look-at-Washington-Post-Data) \n",
    "- [Section 3: Make some Plots!](#Section-3:-Make-some-Plots!)\n",
    "- [Section 4: Initial Look at Models](#Section-4:-Initial-Look-at-Models)\n",
    "- [Section 5: Appendix](#Section-5:-Appendix)\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": false,
    "editable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "source": [
    "## Information about the datasets\n",
    "\n",
    "#### Washingpost dataset\n",
    "In 2015, The Post began tracking more than a dozen details about each killing — including the race of the deceased, the circumstances of the shooting, whether the person was armed and whether the person was experiencing a mental-health crisis — by culling local news reports, law enforcement websites and social media, and by monitoring independent databases such as Killed by Police and Fatal Encounters. The Post conducted additional reporting in many cases.\n",
    "\n",
    "\n",
    "#### Mapping Police Violence\n",
    "This information has been meticulously sourced from the three largest, most comprehensive and impartial crowdsourced databases on police killings in the country: FatalEncounters.org, the U.S. Police Shootings Database and KilledbyPolice.net. We've also done extensive original research to further improve the quality and completeness of the data; searching social media, obituaries, criminal records databases, police reports and other sources to identify the race of 90 percent of all victims in the database.\n",
    "\n",
    "\n",
    "#### Important notes\n",
    "Washingpost sources theur data also from the mapping police violence dataset, but they cleaned the data. Meaning that the  mapping police violence dataset has more entries because it also has some NaN values, which could still be of interest for us."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Data dir path from root of project\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# Load data\n",
    "data_mapping = pd.read_csv(f'{data_dir}/mapping-police-violence-24oct2020.csv')\n",
    "# https://github.com/washingtonpost/data-police-shootings\n",
    "data_wapo = pd.read_csv(f'{data_dir}/fatal-police-shootings-data-wsp.csv')\n",
    "\n",
    "print(f\"{len(data_mapping)} mapping police violence samples\")\n",
    "print(f\"{len(data_wapo)} Washington Post Fatal Police Shootings samples\")\n",
    "print(\"\\nMapping Columns:\")\n",
    "print(', '.join(data_mapping.columns))\n",
    "print(\"\\nWaPo Fatal Shootings Columns:\")\n",
    "print(', '.join(data_wapo.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### <div class='exercise'><b>Section 1: Looking at Mapping Police Violence Dataset</b></div>\n",
    "[▲ Return to contents](#Contents)\n",
    "<div class='exercise'>\n",
    "    \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "display(data_mapping.head())\n",
    "display(data_mapping.info())\n",
    "display(data_mapping.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=data_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have any null values?\n",
    "\n",
    "data_mapping.isnull().values.any()\n",
    "\n",
    "# where are they?\n",
    "\n",
    "for col in data_mapping.columns:\n",
    "    null_count = data_mapping[col].isnull().sum()\n",
    "    print(col, \": \", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the columns which have too many N/A or don't really help us\n",
    "\n",
    "# not used and lots of missing\n",
    "df1 = data_mapping.drop('URL of image of victim', axis=1)\n",
    "\n",
    "# almost all NaN\n",
    "df1 = df1.drop('Off-Duty Killing?', axis=1)\n",
    "\n",
    "# not really used\n",
    "df1 = df1.drop(['Street Address of Incident',\n",
    "                'A brief description of the circumstances surrounding the death',\n",
    "                \"Victim's name\",\n",
    "                'Link to news article or photo of official document',\n",
    "                'ORI Agency Identifier (if available)'],\n",
    "                axis=1)\n",
    "\n",
    "# rename a few annoying columns\n",
    "df1.rename(columns={'Geography (via Trulia methodology based on zipcode population density: http://jedkolko.com/wp-content/uploads/2015/05/full-ZCTA-urban-suburban-rural-classification.xlsx )':'geography'}, inplace=True)\n",
    "df1.rename(columns={'Alleged Weapon (Source: WaPo and Review of Cases Not Included in WaPo Database)':'Alleged Weapon'}, inplace=True)\n",
    "\n",
    "# fix a few of the duplicate groupings\n",
    "\n",
    "df1['Symptoms of mental illness?'] = df1['Symptoms of mental illness?'].str.replace('unknown', 'Unknown')\n",
    "df1['Symptoms of mental illness?'] = df1['Symptoms of mental illness?'].str.replace('Unkown', 'Unknown')\n",
    "\n",
    "df1['Alleged Threat Level (Source: WaPo)'] = df1['Alleged Threat Level (Source: WaPo)'].str.replace('Other', 'other')\n",
    "\n",
    "df1['Fleeing (Source: WaPo)'] = df1['Fleeing (Source: WaPo)'].str.replace('other', 'Other')\n",
    "df1['Fleeing (Source: WaPo)'] = df1['Fleeing (Source: WaPo)'].str.replace('not fleeing', 'Not fleeing')\n",
    "df1['Fleeing (Source: WaPo)'] = df1['Fleeing (Source: WaPo)'].str.replace('Not Fleeing', 'Not fleeing')\n",
    "df1['Fleeing (Source: WaPo)'] = df1['Fleeing (Source: WaPo)'].str.replace('foot', 'Foot')\n",
    "df1['Fleeing (Source: WaPo)'] = df1['Fleeing (Source: WaPo)'].str.replace('car', 'Car')\n",
    "\n",
    "df1['Body Camera (Source: WaPo)'] = df1['Body Camera (Source: WaPo)'].str.replace('no', 'No')\n",
    "df1['Body Camera (Source: WaPo)'] = df1['Body Camera (Source: WaPo)'].str.replace('Dashcam video', 'Dashcam Video')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see what needs further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    display(df1[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the victim's race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autograde": "1.2",
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_mapping[\"Victim's race\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are most of the events taking place?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"State\"].value_counts())\n",
    "display(df1[\"City\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "df1['Cause of death'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Criminal Charges?\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Symptoms of mental illness?\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Unarmed/Did Not Have an Actual Weapon\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Fleeing (Source: WaPo)\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Body Camera (Source: WaPo)\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert all the boolean predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all of the charges together for now\n",
    "df1[\"Criminal Charges?_bool\"]= df1[\"Criminal Charges?\"].apply(lambda x: 0 if x=='No known charges' else 1)\n",
    "\n",
    "# grouping all symptoms not classified as \"yes\"\n",
    "df1[\"Symptoms of mental illness?_bool\"]= df1[\"Symptoms of mental illness?\"].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "\n",
    "# grouping all 'allegedly armed' as \"yes\" vs all other answers\n",
    "df1[\"Unarmed/Did Not Have an Actual Weapon_bool\"]= df1[\"Unarmed/Did Not Have an Actual Weapon\"].apply(lambda x: 1 if x=='Allegedly Armed' else 0)\n",
    "\n",
    "# grouping all spellings of 'not fleeing'\n",
    "df1[\"Fleeing (Source: WaPo)_bool\"]= df1[\"Fleeing (Source: WaPo)\"].apply(lambda x: 0 if x in ['Not fleeing', 'not fleeing', 'Not Fleeing'] else 1)\n",
    "\n",
    "# grouping all spellings of 'no'\n",
    "df1[\"Body Camera (Source: WaPo)_bool\"]= df1[\"Body Camera (Source: WaPo)\"].apply(lambda x: 0 if x in ['No', 'no'] else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these datatypes still need to be recast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversions\n",
    "\n",
    "# age still has some odd values\n",
    "# display(data_mapping[\"Victim's age\"].head())\n",
    "df1[\"Victim's age\"] = data_mapping[\"Victim's age\"].fillna(0)\n",
    "print(df1[\"Victim's age\"].str.isdigit().sum())\n",
    "df1[\"Victim's age\"]= df1[\"Victim's age\"].apply(lambda x: x if str(x).isdigit() else 0).astype(\"int\")\n",
    "\n",
    "\n",
    "# drop a few more NaN\n",
    "#df1 = df1.fillna(str(0))\n",
    "df1.dropna()\n",
    "\n",
    "# recast some of the string categories as type string\n",
    "df1[\"Victim's gender\"] = df1[\"Victim's gender\"].astype('str')\n",
    "df1[\"Victim's race\"] = df1[\"Victim's race\"].astype('str')\n",
    "df1[\"City\"] = df1[\"City\"].astype('str')\n",
    "df1[\"State\"] = df1[\"State\"].astype('str')\n",
    "df1[\"County\"] = df1[\"County\"].astype('str')\n",
    "df1[\"Agency responsible for death\"] = df1[\"Agency responsible for death\"].astype('str')\n",
    "df1[\"Cause of death\"] = df1[\"Cause of death\"].astype('str')\n",
    "df1[\"Official disposition of death (justified or other)\"] = df1[\"Official disposition of death (justified or other)\"].astype('str')\n",
    "df1[\"Symptoms of mental illness?\"] = df1[\"Symptoms of mental illness?\"].astype('str')\n",
    "df1[\"Unarmed/Did Not Have an Actual Weapon\"] = df1[\"Unarmed/Did Not Have an Actual Weapon\"].astype('str')\n",
    "df1[\"Alleged Weapon\"] = df1[\"Alleged Weapon\"].astype('str')\n",
    "df1[\"Fleeing (Source: WaPo)\"] = df1[\"Fleeing (Source: WaPo)\"].astype('str')\n",
    "df1[\"Body Camera (Source: WaPo)\"] = df1[\"Body Camera (Source: WaPo)\"].astype('str')\n",
    "df1[\"Alleged Threat Level (Source: WaPo)\"] = df1[\"Alleged Threat Level (Source: WaPo)\"].astype('str')\n",
    "df1[\"geography\"] = df1[\"geography\"].astype('str')\n",
    "\n",
    "# Add year\n",
    "df1['year'] = pd.DatetimeIndex(df1['Date of Incident (month/day/year)']).year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[\"Victim's gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Data with histogram\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.hist(df1[\"Victim's gender\"], bins=20, alpha = 0.5, edgecolor='k', label='id', color='darkblue')\n",
    "plt.xlabel('Normalized Predictor value')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'ID Value Histogram')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check float features\n",
    "grid_features = [\"Victim's age\", 'Zipcode', 'WaPo ID (If included in WaPo database)', 'MPV ID', \n",
    "                 'Fatal Encounters ID','Criminal Charges?_bool', 'Symptoms of mental illness?_bool',  \n",
    "                 'Unarmed/Did Not Have an Actual Weapon_bool', 'Fleeing (Source: WaPo)_bool',\n",
    "                 'Body Camera (Source: WaPo)_bool' ]\n",
    "\n",
    "scatter = pd.plotting.scatter_matrix(df1[grid_features], alpha=0.4, figsize=(20,20));\n",
    "for ax in scatter.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), rotation = 90)\n",
    "    ax.set_ylabel(ax.get_ylabel(), rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### <div class='exercise'><b>Section 2: Now look at Washington Post Data</b></div>\n",
    "[▲ Return to contents](#Contents)\n",
    "\n",
    "<div class='exercise'>\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_wapo.head())\n",
    "display(data_wapo.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_wapo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset shape: ', data_wapo.shape)\n",
    "\n",
    "data_wapo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have any null values?\n",
    "\n",
    "data_wapo.isnull().values.any()\n",
    "\n",
    "# where are they?\n",
    "\n",
    "for col in data_wapo.columns:\n",
    "    null_count = data_wapo[col].isnull().sum()\n",
    "    print(col, \": \", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the columns which have too many N/A or don't really help us\n",
    "\n",
    "# not really used\n",
    "df2 = data_wapo.drop('name', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dae to datetime pandas value \n",
    "# https://stackoverflow.com/a/33368021/8970591\n",
    "# errors=coerce -> 'if the conversion fails for any particular string then those rows are set to NaT'\n",
    "# errors=raise -> then invalid parsing will raise an exception.\n",
    "df2['date'] = pd.to_datetime(df2['date'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "display(df2.columns)\n",
    "sns.pairplot(data=df2)\n"
   ]
  },
  {
   "source": [
    "### Encoding race values\n",
    "We do miss about 600 entries of race.\n",
    "\n",
    "This is the [original classification](https://github.com/washingtonpost/data-police-shootings):\n",
    "race:\n",
    "\n",
    "`race`:\n",
    "- `W`: White, non-Hispanic\n",
    "- `B`: Black, non-Hispanic\n",
    "- `A`: Asian\n",
    "- `N`: Native American\n",
    "- `H`: Hispanic\n",
    "- `O`: Other\n",
    "- `None`: unknown\n",
    "\n",
    "We want add weights the incident based on the actual amount of each race that lives in the US.\n",
    "\n",
    "Used data [from wikipedia](https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States#Racial_categories):\n",
    "- `W`: 0.601\n",
    "- `B`: 0.134\n",
    "- `A`: 0.059\n",
    "- `N`: 0.013\n",
    "- `H`: 0.185\n",
    "- `O`: 0.008"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Double check our different values \n",
    "display(df2['race'].unique())\n",
    "\n",
    "# Add the weighted race values from wikipedia \n",
    "race_ratios = {\n",
    "    'W': 0.601,\n",
    "    'B': 0.134,\n",
    "    'A': 0.059,\n",
    "    'N': 0.013,\n",
    "    'H': 0.185,\n",
    "    'O': 0.008,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO:Impute the unkown values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to recast some of the object types as correct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversions\n",
    "# df2['name'] = df2['name'].astype('category')\n",
    "df2['manner_of_death'] = df2['manner_of_death'].astype('category')\n",
    "df2['armed'] = df2['armed'].astype('str')\n",
    "df2['gender'] = df2['gender'].astype('str')\n",
    "df2['race'] = df2['race'].astype('str')\n",
    "df2['city'] = df2['state'].astype('str')\n",
    "df2['threat_level'] = df2['threat_level'].astype('str')\n",
    "df2['flee'] = df2['flee'].astype('str')\n",
    "df2['signs_of_mental_illness'] = df2['signs_of_mental_illness'].astype('int')\n",
    "df2['body_camera'] = df2['body_camera'].astype('str')\n",
    "df2['is_geocoding_exact'] = df2['is_geocoding_exact'].astype('str')\n",
    "\n",
    "# Add year\n",
    "df2['year'] = pd.DatetimeIndex(df2['date']).year\n",
    "\n",
    "# check again\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### <div class='exercise'><b>Section 3: Make some Plots!</b></div>\n",
    "[▲ Return to contents](#Contents)\n",
    "\n",
    "<div class='exercise'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_counts_barchart(df_plot, class_key, verbose=False, normalize=False,\n",
    "                               is_custom=False, custom_values=None):\n",
    "    # Grab the value counts, and use custom ones if needed\n",
    "    # e.g. date or categroical group\n",
    "    if is_custom:\n",
    "        df_values = custom_values\n",
    "    else:\n",
    "        df_values = df_plot[class_key].value_counts(normalize=normalize)\n",
    "    \n",
    "    if verbose:\n",
    "        display(df_values)\n",
    "    \n",
    "    # Create the plot ax object\n",
    "    ax = df_values.plot(kind='bar', figsize=(14,8))\n",
    "    \n",
    "    # Set and rotate the labels for better readability \n",
    "#     ax.set_xticklabels(preds, rotation=45, direction=\"in\", rotation_mode=\"anchor\")\n",
    "    ax.tick_params(axis='x', rotation=45, direction=\"in\",)\n",
    "    \n",
    "    # Set the labels\n",
    "    ax.set_xlabel(class_key.capitalize(), fontsize=15)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=15)\n",
    "    \n",
    "    # Create the title extenstion and then set title\n",
    "    title_ext_norm = \" - Normalized\" if normalize == True else \"\"\n",
    "    ax.set_title(f\"Incident frequency by {class_key.capitalize()}{title_ext_norm}\", fontsize=18)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### State by state \n",
    "We see that CA, TX and FL by far have the most police indcident. If you look at the normalized (so by ratio), chart you see an even bigger."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# WSP: Get incident state counts\n",
    "per_state_df = df2.groupby([\"state\"])\n",
    "\n",
    "# Plot state by state count \n",
    "plot_value_counts_barchart(df2, 'state', verbose=False, normalize=False)\n",
    "\n",
    "# Plot state by state count \n",
    "plot_value_counts_barchart(df2, 'state', verbose=False, normalize=True)"
   ]
  },
  {
   "source": [
    "### Year by year for all incidents\n",
    "There doesn't seem to be a very clear indication that the indicents grew on year to year basis \n",
    "\n",
    "This data was sourced at the 10th month of 2020, so 2020 could at the end of this year also be similar to the previous years"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state by year \n",
    "df_by_year = df2['date'].groupby([df2.date.dt.year]).agg('count')\n",
    "plot_value_counts_barchart(df2, 'year', is_custom=True, custom_values=df_by_year)"
   ]
  },
  {
   "source": [
    "### Indicents by race\n",
    "\n",
    "This is the [original classification](https://github.com/washingtonpost/data-police-shootings):\n",
    "race:\n",
    "\n",
    "`race`:\n",
    "- `W`: White, non-Hispanic\n",
    "- `B`: Black, non-Hispanic\n",
    "- `A`: Asian\n",
    "- `N`: Native American\n",
    "- `H`: Hispanic\n",
    "- `O`: Other\n",
    "- `None`: unknown"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weighted values\n",
    "df_by_race = df2['race'].value_counts()\n",
    "df_by_race.head()\n",
    "\n",
    "\n",
    "# df_race_weighted = TODO \n",
    "\n",
    "# Plot state by race\n",
    "plot_value_counts_barchart(df2, 'race')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# scatter of various predictors\n",
    "x = df2['age']\n",
    "y = df2['race']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(data=df2, \n",
    "                x=x, \n",
    "                y=y, \n",
    "                hue=\"threat_level\")\n",
    "#plt.scatter(x,y, label='Training data', color='darkblue')\n",
    "#plt.scatter(x_test,y_test, label='Testing data', color='lightblue')\n",
    "plt.title('Age and Race Filtered by Threat Level')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Race')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# scatter of various predictors\n",
    "x = df2['id']\n",
    "y = df2['age']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(data=df2, \n",
    "                x=x, \n",
    "                y=y, \n",
    "                hue=\"signs_of_mental_illness\")\n",
    "#plt.scatter(x,y, label='Training data', color='darkblue')\n",
    "#plt.scatter(x_test,y_test, label='Testing data', color='lightblue')\n",
    "plt.title('Age Filtered by Signs of Mental Illness')\n",
    "plt.xlabel('ID')\n",
    "plt.ylabel('Age')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# scatter of various predictors\n",
    "x = df2['year']\n",
    "y = df2['id']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.stripplot(data=df2, \n",
    "              x=x, \n",
    "              y=y, \n",
    "              hue=\"gender\",\n",
    "              dodge=True)\n",
    "plt.title('Age and Race Filtered by Threat Level')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('ID')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# scatter of various predictors\n",
    "x = df2['age']\n",
    "y = df2['flee']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.stripplot(data=df2, \n",
    "              x=x, \n",
    "              y=y, \n",
    "              hue=\"gender\",\n",
    "              dodge=True)\n",
    "plt.title('Who is fleeing the scene?')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('Flee?')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# scatter of various predictors\n",
    "x = df1[\"Victim's race\"]\n",
    "y = df1[\"Criminal Charges?_bool\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.stripplot(data=df2, \n",
    "              x=x, \n",
    "              y=y, \n",
    "              dodge=True)\n",
    "plt.title('Who is fleeing the scene?')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('Flee?')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate correlations\n",
    "corr = df1.corr()\n",
    " \n",
    "# Heatmap\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate correlations\n",
    "corr = df2.corr()\n",
    " \n",
    "# Heatmap\n",
    "sns.heatmap(corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### <div class='exercise'><b>Section 4: Initial Look at Models</b></div>\n",
    "[▲ Return to contents](#Contents)\n",
    "\n",
    "<div class='exercise'>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### <div class='exercise'><b>Section 5: Appendix</b></div>\n",
    "[▲ Return to contents](#Contents)\n",
    "<div class='exercise'>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### End of Notebook"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "jupytext": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('cs109a': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fb770c46dfe1008d9ad3c963650c242536c0ef7ec1256f653cad95c634da1e7d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}